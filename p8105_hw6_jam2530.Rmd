---
title: "P8105_hw6_jam2530"
author: "Jenna Mohammed"
date: '2023-11-28'
output: github_document
---

```{r, message=FALSE, warning=FALSE}
library(readr)
library(tidyverse)
library(modelr)
library(p8105.datasets)
```

# Problem 1
```{r}
urlfile = "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"

data <- read_csv(url(urlfile))
```

# Problem 2 

#### Loading in and cleaning data

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())

view(weather_df)
```

#### Fitting a regression model 

```{r}
fit <- lm(tmax ~ tmin + prcp, data = weather_df) |>
  broom::tidy() |> 
  knitr::kable(digits = 3)
```

#### Creating function for bootstrap

```{r}
boot_sample = function(weather_df) {
  sample_frac(weather_df, replace = TRUE)
}
```

#### Creating Estimate and Plot for R^2

```{r}
r_squared = 
  weather_df |>
  bootstrap(n = 5000) |>
  mutate(
    models = map(.x = strap, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::glance)) |>
  unnest(results)

view(r_squared)

r_squared_plot <- r_squared |>
  ggplot(aes(x = r.squared)) + 
  geom_density() +
  labs( 
    x = "R Squared",
    y = "Density",
    title = "Plot of R Squared and Density")

print(r_squared_plot)

```

#### Performing a 95% Confidence Interval for R^2


```{r}
r_squared |>
  summarize(
    lower_limit = quantile(r.squared, 0.025), 
    upper_limit = quantile(r.squared, 0.975)) |>
  knitr::kable(digits = 3)
```

The 95% confidence interval for R^2 is (0.887, 0.939)

#### Creating estimate for log(beta_0 * beta_1)

```{r}

log_estimate= 
  weather_df |>
  modelr::bootstrap(n = 5000) |>
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::tidy)
  ) |>
  select(-strap, -models) |>
  unnest(results) |>
  select(.id, term, estimate) |>
  pivot_wider(
    names_from = "term", 
    values_from = "estimate"
  ) |>
  mutate(
    log_function = log(`(Intercept)`*tmin)
  ) 

log_plot<- log_estimate |>
  ggplot(aes(x = log_function)) + 
  geom_density() +
  labs( 
    x = "Log Function",
    y = "Density",
    title = "Plot of Log Function and Density")

print(log_plot)
```

#### Performing a 95% CI for log 

```{r}
log_estimate |>
  summarize(
    lower_limit = quantile(log_function, 0.025), 
    upper_limit = quantile(log_function, 0.975)) |>
  knitr::kable(digits = 3)
```


# Problem 3 

#### Reading in and cleaning the data

```{r}

birthweight_df = read_csv("./birthweight.csv")

birthweight_df |>
  janitor::clean_names() |>
  drop_na() |>
  mutate(
    babysex = factor(babysex, labels = c("male", "female")
  ), 
   frace = factor(frace, labels = c("White", "Black", "Asian", "Puerto Rican", "Other")),
   mrace = factor(mrace, labels = c("White", "Black", "Asian", "Puerto Rican")
  )) 

view(birthweight_df)
```


#### Regression model for birthweight

```{r}
regression_model = lm(bwt ~ malform + smoken + gaweeks + babysex , data = birthweight_df)

residual_plot <- birthweight_df |>
  add_predictions(regression_model) |>
  add_residuals(regression_model) |>
  ggplot(aes(x = pred, y = resid)) +
  geom_point() +
  geom_smooth() +
  labs(
    x = "Fitted",
    y = "Residuals",
    title = "Plot of Fitted values and Residuals"
  )

print(residual_plot)
```

#### Comparing model to other models 


- We will create model 2 using `blength` and `gaweeks` as predictors 
- We will create model 3 using `bhead`, `blength`, `babysex`, anf their interactions as predictors

```{r}

 model_2 = lm(bwt ~ blength + gaweeks, data = birthweight_df)

 model_3 = lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex, data = birthweight_df)
```

#### Testing the models

```{r}
cv_model <- birthweight_df |> 
  crossv_mc( 100) |>
  mutate(
    train = map(train,as_tibble),
    test = map(test,as_tibble)
  )
```

```{r}
cv_model =
    cv_model  |>
  mutate(
    m1 = map(train, ~ lm(bwt ~ malform + smoken + gaweeks + babysex , data = .x)),
    m2 = map(train, ~lm(bwt ~ blength + gaweeks,  data = .x)),
    m3 = map(train, ~lm(bwt ~ babysex + blength + bhead + babysex * blength + babysex * bhead + blength * bhead + babysex * blength * bhead, data = .x))
    ) |>
  
  mutate(
    rmse_m1 = map2_dbl(m1, test, ~rmse(model = .x, data = .y)),
    rmse_m2 = map2_dbl(m2, test, ~rmse(model = .x, data = .y)),
    rmse_m3 = map2_dbl(m3, test, ~rmse(model = .x, data = .y)))
```

```{r}
cv_model |> 
  select(starts_with("rmse")) |>
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") |>
  mutate(model = fct_inorder(model)) |>
  ggplot(aes(x = model, y = rmse, fill = model)) + 
  geom_violin()+
  labs(
    x = "Model",
    y = "RMSE",
    title = "Plot of Model against RMSE"
  )
```

The plot above shows that model 3 is the preferred model. Compared to the other two models, model 3 has the lowest RMSE, meaning that is has the smallest difference between the predicted and actual values